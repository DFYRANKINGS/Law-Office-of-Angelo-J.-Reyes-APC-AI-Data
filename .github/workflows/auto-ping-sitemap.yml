name: "üåê Build Pages + Sitemaps + Robots & Auto-Ping on Push"

on:
  push:
    branches: [ main ]
    paths:
      - 'schemas/**'
      - 'ai-generators/**'
      - 'generate_sitemaps.py'
      - 'generate_robots.py'
      - 'CNAME'
      - '.github/workflows/auto-ping-sitemap.yml'
  workflow_dispatch:

permissions:
  contents: write

jobs:
  ping-search-engines:
    runs-on: ubuntu-latest
    steps:
      - name: üì• Checkout Repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: üêç Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: üì¶ Install Dependencies
        run: |
          python -m pip install --upgrade pip
          pip install pyyaml

      # 1) Build public pages so sitemap has real HTML to list
      - name: üß± Build Public Pages
        run: python ai-generators/build_public_pages.py

      - name: üíæ Commit Pages (if changed)
        run: |
          git config user.name  "github-actions[bot]"
          git config user.email "41898282+github-actions[bot]@users.noreply.github.com"
          git add index.html about.html services.html testimonials.html faqs.html help.html contact.html .nojekyll
          git commit -m "AUTO: Build public pages" || echo "No page changes to commit"
          git push || true

      # 2) Generate BOTH sitemaps (HTML + AI)
      - name: üó∫Ô∏è Generate Sitemaps
        run: python generate_sitemaps.py --include-all-html

      - name: üíæ Commit Sitemaps (if changed)
        run: |
          git add sitemap.xml ai-sitemap.xml
          git commit -m "AUTO: Update sitemaps" || echo "No sitemap changes to commit"
          git push || true

      # 3) Generate robots.txt at repo root
      - name: ü§ñ Generate robots.txt
        run: python generate_robots.py

      - name: üíæ Commit robots.txt (if changed)
        run: |
          git add robots.txt
          git commit -m "AUTO: Update robots.txt" || echo "No robots changes to commit"
          git push || true

      # 4) Ping Google & Bing with the *Pages* sitemap (and optionally AI sitemap)
      - name: üì° Ping Search Engines
        run: |
          OWNER_REPO="${{ github.repository }}"
          OWNER="${OWNER_REPO%/*}"
          REPO="${OWNER_REPO#*/}"
          BRANCH="${{ github.ref_name || 'main' }}"
          BASE="https://${OWNER}.github.io/${REPO}"

          # Prefer custom domain if CNAME exists
          if [ -f CNAME ]; then
            HOST=$(cat CNAME | tr -d '\r' | sed 's#http://##; s#https://##' | tr -d '/')
            if [ -n "$HOST" ]; then BASE="https://${HOST}"; fi
          fi

          PAGE_SITEMAP="${BASE}/sitemap.xml"
          AI_SITEMAP="https://raw.githubusercontent.com/${OWNER}/${REPO}/${BRANCH}/ai-sitemap.xml"

          echo "üìÑ Page sitemap: ${PAGE_SITEMAP}"
          echo "ü§ñ AI sitemap:   ${AI_SITEMAP}"

          echo "‚Üí Notifying Google (page sitemap)‚Ä¶"
          curl -s -o /dev/null -w "%{http_code}\n" "https://www.google.com/ping?sitemap=${PAGE_SITEMAP}" || true

          echo "‚Üí Notifying Bing (page sitemap)‚Ä¶"
          curl -s -o /dev/null -w "%{http_code}\n" "https://www.bing.com/ping?sitemap=${PAGE_SITEMAP}" || true

          # Optional: also ping AI sitemap (harmless if ignored)
          echo "‚Üí (Optional) Notifying Google (AI sitemap)‚Ä¶"
          curl -s -o /dev/null -w "%{http_code}\n" "https://www.google.com/ping?sitemap=${AI_SITEMAP}" || true

          echo "‚Üí (Optional) Notifying Bing (AI sitemap)‚Ä¶"
          curl -s -o /dev/null -w "%{http_code}\n" "https://www.bing.com/ping?sitemap=${AI_SITEMAP}" || true
